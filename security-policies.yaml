# 网络策略 - 限制Pod间通信
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: kafka-network-policy
  namespace: kafka
spec:
  podSelector:
    matchLabels:
      app: kafka
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: kafka-client
    - podSelector:
        matchLabels:
          app: zookeeper
    ports:
    - protocol: TCP
      port: 9092
    - protocol: TCP
      port: 9093
    - protocol: TCP
      port: 9999
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: zookeeper
    ports:
    - protocol: TCP
      port: 2181
    - protocol: TCP
      port: 2182
  - to: []
    ports:
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53

---
# Zookeeper网络策略
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: zookeeper-network-policy
  namespace: kafka
spec:
  podSelector:
    matchLabels:
      app: zookeeper
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: kafka
    - podSelector:
        matchLabels:
          app: kafka-client
    ports:
    - protocol: TCP
      port: 2181
    - protocol: TCP
      port: 2182
  - from:
    - podSelector:
        matchLabels:
          app: zookeeper
    ports:
    - protocol: TCP
      port: 2888
    - protocol: TCP
      port: 3888
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: zookeeper
    ports:
    - protocol: TCP
      port: 2888
    - protocol: TCP
      port: 3888
  - to: []
    ports:
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53

---
# Pod安全策略
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: kafka-psp
spec:
  privileged: false
  allowPrivilegeEscalation: false
  requiredDropCapabilities:
    - ALL
  volumes:
    - 'configMap'
    - 'emptyDir'
    - 'projected'
    - 'secret'
    - 'downwardAPI'
    - 'persistentVolumeClaim'
  runAsUser:
    rule: 'MustRunAsNonRoot'
  seLinux:
    rule: 'RunAsAny'
  fsGroup:
    rule: 'RunAsAny'

---
# 备份CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: kafka-backup
  namespace: kafka
spec:
  schedule: "0 2 * * *"  # 每天凌晨2点
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: google/cloud-sdk:alpine
            command:
            - /bin/sh
            - -c
            - |
              # 备份Kafka配置
              kubectl get configmaps -n kafka -o yaml > /backup/configmaps-$(date +%Y%m%d).yaml
              kubectl get secrets -n kafka -o yaml > /backup/secrets-$(date +%Y%m%d).yaml
              kubectl get certificates -n kafka -o yaml > /backup/certificates-$(date +%Y%m%d).yaml
              
              # 上传到GCS (需要配置服务账号)
              # gsutil cp /backup/* gs://your-backup-bucket/kafka/
              
              # 清理7天前的备份
              find /backup -name "*.yaml" -mtime +7 -delete
            volumeMounts:
            - name: backup-storage
              mountPath: /backup
          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-pvc
          restartPolicy: OnFailure

---
# 备份存储
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: backup-pvc
  namespace: kafka
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi

---
# 资源配额
apiVersion: v1
kind: ResourceQuota
metadata:
  name: kafka-quota
  namespace: kafka
spec:
  hard:
    requests.cpu: "10"
    requests.memory: 20Gi
    limits.cpu: "20"
    limits.memory: 40Gi
    persistentvolumeclaims: "10"
    pods: "20"

---
# 限制范围
apiVersion: v1
kind: LimitRange
metadata:
  name: kafka-limits
  namespace: kafka
spec:
  limits:
  - default:
      cpu: "1"
      memory: "2Gi"
    defaultRequest:
      cpu: "100m"
      memory: "256Mi"
    type: Container 