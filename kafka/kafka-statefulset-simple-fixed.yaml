apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: confluent-kafka
  labels:
    app: kafka
spec:
  serviceName: kafka-headless
  replicas: 1
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      securityContext:
        runAsUser: 0  # 使用root用户避免权限问题
        runAsGroup: 0
        fsGroup: 0
      containers:
      - name: kafka
        image: apache/kafka:latest
        ports:
        - containerPort: 9092
          name: kafka
        - containerPort: 9093
          name: controller
        env:
        - name: KAFKA_BROKER_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['apps.kubernetes.io/pod-index']
        - name: KAFKA_PROCESS_ROLES
          value: "broker,controller"
        - name: KAFKA_NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['apps.kubernetes.io/pod-index']
        - name: KAFKA_CONTROLLER_QUORUM_VOTERS
          value: "0@kafka-0.kafka-headless.confluent-kafka.svc.cluster.local:9093"
        - name: KAFKA_LISTENERS
          value: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093"
        - name: KAFKA_ADVERTISED_LISTENERS
          value: "PLAINTEXT://kafka-0.kafka-headless.confluent-kafka.svc.cluster.local:9092"
        - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
          value: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
        - name: KAFKA_CONTROLLER_LISTENER_NAMES
          value: "CONTROLLER"
        - name: KAFKA_INTER_BROKER_LISTENER_NAME
          value: "PLAINTEXT"
        - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: "1"
        - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
          value: "1"
        - name: KAFKA_TRANSACTION_STATE_LOG_MIN_ISR
          value: "1"
        - name: KAFKA_LOG_DIRS
          value: "/var/lib/kafka/data"
        - name: CLUSTER_ID
          value: "Y2x1c3Rlci1pZC1mb3Ita2FmY2EtdGVzdA"
        
        command:
        - sh
        - -c
        - |
          set -e
          
          echo "开始初始化Kafka..."
          
          # 设置目录权限 - 使用正确的用户
          chown -R appuser:appuser /var/lib/kafka/data || true
          
          # 清理可能存在的问题目录
          rm -rf /var/lib/kafka/data/lost+found 2>/dev/null || true
          
          # 确保Kafka数据目录存在
          mkdir -p /var/lib/kafka/data
          
          # 生成唯一的cluster ID
          CLUSTER_ID="Y2x1c3Rlci1pZC1mb3Ita2FmY2EtdGVzdA"
          
          # 修改现有的server.properties文件
          cat > /opt/kafka/config/server.properties << 'EOF'
          # Basic Kafka configuration
          process.roles=broker,controller
          node.id=0
          controller.quorum.voters=0@kafka-0.kafka-headless.confluent-kafka.svc.cluster.local:9093
          
          # Listener configuration
          listeners=PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
          advertised.listeners=PLAINTEXT://kafka-0.kafka-headless.confluent-kafka.svc.cluster.local:9092
          listener.security.protocol.map=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
          controller.listener.names=CONTROLLER
          inter.broker.listener.name=PLAINTEXT
          
          # Log configuration
          log.dirs=/var/lib/kafka/data
          num.network.threads=3
          num.io.threads=8
          socket.send.buffer.bytes=102400
          socket.receive.buffer.bytes=102400
          socket.request.max.bytes=104857600
          
          # Replication settings for single-node cluster
          default.replication.factor=1
          min.insync.replicas=1
          offsets.topic.replication.factor=1
          transaction.state.log.replication.factor=1
          transaction.state.log.min.isr=1
          
          # Other settings
          num.partitions=1
          num.recovery.threads.per.data.dir=1
          log.retention.hours=168
          log.segment.bytes=1073741824
          log.retention.check.interval.ms=300000
          log.cleanup.policy=delete
          
          # Group settings
          group.initial.rebalance.delay.ms=0
          EOF
          
          # 检查是否已经格式化过
          if [ ! -f "/var/lib/kafka/data/meta.properties" ]; then
            echo "格式化Kafka存储..."
            /opt/kafka/bin/kafka-storage.sh format \
              --config /opt/kafka/config/server.properties \
              --cluster-id $CLUSTER_ID \
              --ignore-formatted
            echo "格式化完成"
          else
            echo "存储已经格式化，跳过格式化步骤"
          fi
          
          echo "启动Kafka服务器..."
          exec /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties
        
        volumeMounts:
        - name: kafka-data
          mountPath: /var/lib/kafka/data
        
        resources:
          requests:
            cpu: 500m
            memory: 2Gi
          limits:
            cpu: 1000m
            memory: 4Gi
        
        readinessProbe:
          tcpSocket:
            port: 9092
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          
        livenessProbe:
          tcpSocket:
            port: 9092
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 5
  
  volumeClaimTemplates:
  - metadata:
      name: kafka-data
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: ssd
      resources:
        requests:
          storage: 10Gi 